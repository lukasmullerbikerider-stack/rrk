import os
import time
import json
import logging
import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
from jdatetime import datetime as jdatetime
import subprocess
import sys
import tempfile

# ----------------------------------
# تنظیمات عمومی
# ----------------------------------
st.set_page_config(page_title="RRK Company Extractor", page_icon="🏢", layout="wide")

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Create a temporary directory for each run
user_data_dir = tempfile.mkdtemp()

# Setup Chrome options
chrome_options = Options()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--incognito")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--window-size=1400,1000")
chrome_options.add_argument("--disable-notifications")

# ----------------------------------
# توابع Selenium
# ----------------------------------
def scrape_company_ads(query):
    """جمع‌آوری آگهی‌های rrk.ir"""
    driver, wait = setup_driver()
    ad_data = []

    try:
        driver.get("https://www.rrk.ir/")
        search_box = wait.until(EC.presence_of_element_located((By.ID, "P0_SEARCH_ITEM")))
        search_box.clear()
        search_box.send_keys(query)
        driver.find_element(By.ID, "BTN_ADVANCEDSEARCH").click()
        time.sleep(3)

        # ورود به بخش آگهی‌ها
        wait.until(EC.element_to_be_clickable((By.CLASS_NAME, "t-LinksList-link"))).click()
        time.sleep(5)

        current_page = 1
        while True:
            ad_links = get_links(driver)
            if not ad_links:
                break

            for tag in ad_links:
                href = tag.get("href")
                if not href.startswith("/ords/r/rrs/rrs-front/f-detail-ad"):
                    continue
                url = "https://rrk.ir" + href

                driver.execute_script("window.open('');")
                driver.switch_to.window(driver.window_handles[1])
                driver.get(url)
                soup = BeautifulSoup(driver.page_source, "html.parser")

                try:
                    data = extract_fields(driver, soup)
                    data["url"] = url
                    ad_data.append(data)
                except Exception as e:
                    logging.warning(f"⚠️ خطا در استخراج آگهی: {e}")
                finally:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                    time.sleep(2)

            # صفحه بعد
            next_buttons = driver.find_elements(By.CSS_SELECTOR, "ul.a-GV-pageSelector-list li button.a-GV-pageButton")
            next_btn = next((b for b in next_buttons if b.text.isdigit() and int(b.text) == current_page + 1), None)
            if not next_btn:
                break
            driver.execute_script("arguments[0].click();", next_btn)
            current_page += 1
            time.sleep(5)

    except Exception as e:
        logging.error(f"❌ خطا: {e}")
    finally:
        driver.quit()

    return ad_data

def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--user-data-dir=/tmp/unique_profile_" + str(time.time()))
    # Merge with global chrome_options for better compatibility
    for arg in chrome_options.arguments:
        if arg not in options.arguments:
            options.add_argument(arg.split('=')[0] if '=' in arg else arg)
    driver = webdriver.Chrome(options=options)

    driver.implicitly_wait(10)
    wait = WebDriverWait(driver, 60)
    return driver, wait

def get_links(driver):
    soup = BeautifulSoup(driver.page_source, "html.parser")
    return soup.select("a[href*='/ords/r/rrs/rrs-front/f-detail-ad']")

def extract_fields(driver, soup):
    """استخراج فیلدهای آگهی از صفحه جزئیات"""
    fields = {
        "شماره پیگیری": driver.find_element(By.ID, "P28_REFERENCENUMBER").get_attribute("value"),
        "شماره نامه": driver.find_element(By.ID, "P28_INDIKATORNUMBER").get_attribute("value"),
        "تاریخ نامه": driver.find_element(By.ID, "P28_SABTDATE").get_attribute("value"),
        "نام شرکت": driver.find_element(By.ID, "P28_COMPANYNAME").get_attribute("value"),
        "شناسه ملی شرکت": driver.find_element(By.ID, "P28_SABTNATIONALID").get_attribute("value"),
        "شماره ثبت": driver.find_element(By.ID, "P28_SABTNUMBER").get_attribute("value"),
        "شماره روزنامه": driver.find_element(By.ID, "P28_NEWSPAPERNO").get_attribute("value"),
        "تاریخ روزنامه": driver.find_element(By.ID, "P28_NEWSPAPERDATE").get_attribute("value"),
        "شماره صفحه روزنامه": driver.find_element(By.ID, "P28_PAGENUMBER").get_attribute("value"),
        "تعداد نوبت انتشار": driver.find_element(By.ID, "P28_HCNEWSSTAGE").get_attribute("value")
    }
    dynamic = soup.select_one("a-dynamic-content")
    fields["متن آگهی"] = dynamic.get_text(" ", strip=True) if dynamic else soup.get_text(" ", strip=True)
    return fields

# 2️⃣ --- تنظیم API Key ---
apikey = "AIzaSyAALSr7TI81SZ6e0X9tLk14GJJk37CkMgQ"
# ------------------ توابع کمکی ------------------

def llm(data):
    """ارسال داده به مدل Gemini و دریافت خروجی JSON"""
    try:
        prompt = json.dumps(data, ensure_ascii=False, indent=2)
        system_instruction = """
        نقش: تحلیلگر حقوقی و شرکتی متخصص در روزنامه رسمی.
        وظیفه: استخراج اعضای شرکت از آگهی‌ها به ترتیب تاریخی.
        خروجی JSON طبق قالب مشخص.
        """

        model = genai.GenerativeModel(
            model_name="gemini-2.5-pro",
            system_instruction=system_instruction
        )

        response = model.generate_content(
            prompt,
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.2
            }
        )

        result = json.loads(response.text)
        return result

    except Exception as e:
        st.error(f"❌ خطا در پردازش مدل: {e}")
        return None


def shamsi_to_miladi(date_str):
    if not date_str or date_str == 'null':
        return datetime.now()
    try:
        year, month, day = map(int, date_str.split('/'))
        return jdatetime.date(year, month, day).togregorian()
    except Exception:
        return datetime.now()


def charts(data):
    """نمایش چارت اعضای شرکت در Streamlit"""
    if not data or 'اعضای سابق شرکت' not in data:
        st.error("❌ ساختار داده نامعتبر است.")
        return

    df = pd.DataFrame(data['اعضای سابق شرکت'])
    df['تاریخ_شروع_میلادی'] = df['تاریخ شروع'].apply(shamsi_to_miladi)
    df['تاریخ_پایان_میلادی'] = df['تاریخ پایان'].apply(shamsi_to_miladi)

    def categorize_position(position):
        if not isinstance(position, str): return 'سایر'
        if 'مدیرعامل' in position:
            return 'مدیرعامل'
        elif any(x in position for x in ['رئیس', 'نایب', 'عضو هیئت', 'عضو هیات']):
            return 'هیئت مدیره'
        elif 'بازرس' in position:
            return 'بازرس'
        else:
            return 'سایر'

    df['دسته'] = df['سمت'].apply(categorize_position)
    df = df.sort_values('تاریخ_شروع_میلادی')

    color_map = {
        'مدیرعامل': '#ff7f0e',
        'هیئت مدیره': '#1f77b4',
        'بازرس': '#8c564b',
        'سایر': '#7f7f7f'
    }

    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=('تایم‌لاین کامل اعضای شرکت', 'تایم‌لاین مدیرعامل و رئیس هیئت', 'آمار سمت‌ها'),
        specs=[[{"type": "scatter"}], [{"type": "scatter"}], [{"type": "bar"}]],
        vertical_spacing=0.12
    )

    for _, row in df.iterrows():
        color = color_map.get(row['دسته'], '#7f7f7f')
        fig.add_trace(
            go.Scatter(
                x=[row['تاریخ_شروع_میلادی'], row['تاریخ_پایان_میلادی']],
                y=[row['نام'], row['نام']],
                mode='lines+markers',
                name=row['سمت'],
                line=dict(color=color, width=5),
                marker=dict(size=7, color=color),
                hovertemplate=f"{row['نام']}<br>{row['سمت']}<br>{row['تاریخ شروع']} تا {row['تاریخ پایان']}"
            ),
            row=1, col=1
        )

    filtered = df[df['دسته'].isin(['مدیرعامل', 'هیئت مدیره'])]
    for _, row in filtered.iterrows():
        color = color_map.get(row['دسته'], '#7f7f7f')
        fig.add_trace(
            go.Scatter(
                x=[row['تاریخ_شروع_میلادی'], row['تاریخ_پایان_میلادی']],
                y=[f"{row['نام']} ({row['سمت']})"] * 2,
                mode='lines+markers',
                line=dict(color=color, width=6)
            ),
            row=2, col=1
        )

    counts = df['دسته'].value_counts()
    fig.add_trace(
        go.Bar(x=counts.index, y=counts.values, text=counts.values, textposition='auto'),
        row=3, col=1
    )

    fig.update_layout(height=1200, title="📊 داشبورد اعضای شرکت", template='plotly_white')
    st.plotly_chart(fig, use_container_width=True)


# ------------------ رابط کاربری Streamlit ------------------
st.set_page_config(page_title="RRK Analyzer", layout="wide")
st.title("🏢 RRK.ir – Company Ads Extractor & Analyzer")

tab1, tab2, tab3 = st.tabs(["🕵️ استخراج اطلاعات شرکت", "📂 بررسی اعضای شرکت", "📈 تایم‌لاین اعضای شرکت"])

# --- تب 1 ---
with tab1:
    st.info("در این بخش می‌توانید با وارد کردن نام شرکت، آگهی‌ها را جمع‌آوری کنید (نمونه‌سازی).")
    query = st.text_input("🔍 نام شرکت یا شناسه ملی:")
    if st.button("شروع استخراج"):
        st.warning("این بخش هنوز به تابع scrape_company_ads نیاز دارد (در این نسخه غیرفعال است).")

# --- تب 2 ---
with tab2:
    st.markdown("### 📁 بارگذاری فایل JSON از آگهی‌ها")
    uploaded = st.file_uploader("فایل JSON را انتخاب کنید", type=["json"])
    if uploaded:
        ads = json.load(uploaded)
        st.success(f"{len(ads)} رکورد بارگذاری شد.")
        st.dataframe(pd.DataFrame(ads))
        if st.button("🚀 تحلیل با Gemini"):
            result = llm(ads)
            if result:
                st.json(result)
                st.download_button("📥 دانلود خروجی", data=json.dumps(result, ensure_ascii=False, indent=2),
                                   file_name="company_members.json", mime="application/json")

# --- تب 3 ---
with tab3:
    st.markdown("### 📈 بارگذاری فایل تحلیل‌شده اعضای شرکت (company_members.json)")
    uploaded2 = st.file_uploader("📂 فایل JSON را انتخاب کنید", type=["json"], key="tab3uploader")
    if uploaded2:
        data = json.load(uploaded2)
        charts(data)
