import os
import time
import json
import logging
import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
from jdatetime import datetime as jdatetime
# ----------------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
# ----------------------------------
st.set_page_config(page_title="RRK Company Extractor", page_icon="ğŸ¢", layout="wide")

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

chrome_options = Options()
#chrome_options.add_argument("--headless")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--window-size=1400,1000")
chrome_options.add_argument("--disable-notifications")

# ----------------------------------
# ØªÙˆØ§Ø¨Ø¹ Selenium
# ----------------------------------
def scrape_company_ads(query):
    """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ rrk.ir"""
    driver, wait = setup_driver()
    ad_data = []

    try:
        driver.get("https://www.rrk.ir/")
        search_box = wait.until(EC.presence_of_element_located((By.ID, "P0_SEARCH_ITEM")))
        search_box.clear()
        search_box.send_keys(query)
        driver.find_element(By.ID, "BTN_ADVANCEDSEARCH").click()
        time.sleep(3)

        # ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ø¨Ø®Ø´ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§
        wait.until(EC.element_to_be_clickable((By.CLASS_NAME, "t-LinksList-link"))).click()
        time.sleep(5)

        current_page = 1
        while True:
            ad_links = get_links(driver)
            if not ad_links:
                break

            for tag in ad_links:
                href = tag.get("href")
                if not href.startswith("/ords/r/rrs/rrs-front/f-detail-ad"):
                    continue
                url = "https://rrk.ir" + href

                driver.execute_script("window.open('');")
                driver.switch_to.window(driver.window_handles[1])
                driver.get(url)
                soup = BeautifulSoup(driver.page_source, "html.parser")

                try:
                    data = extract_fields(driver, soup)
                    data["url"] = url
                    ad_data.append(data)
                except Exception as e:
                    logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ú¯Ù‡ÛŒ: {e}")
                finally:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                    time.sleep(2)

            # ØµÙØ­Ù‡ Ø¨Ø¹Ø¯
            next_buttons = driver.find_elements(By.CSS_SELECTOR, "ul.a-GV-pageSelector-list li button.a-GV-pageButton")
            next_btn = next((b for b in next_buttons if b.text.isdigit() and int(b.text) == current_page + 1), None)
            if not next_btn:
                break
            driver.execute_script("arguments[0].click();", next_btn)
            current_page += 1
            time.sleep(5)

    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§: {e}")
    finally:
        driver.quit()

    return ad_data

def setup_driver():
    driver = webdriver.Chrome(options=chrome_options)
    driver.implicitly_wait(10)
    wait = WebDriverWait(driver, 60)
    return driver, wait

def get_links(driver):
    soup = BeautifulSoup(driver.page_source, "html.parser")
    return soup.select("a[href*='/ords/r/rrs/rrs-front/f-detail-ad']")

def extract_fields(driver, soup):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¢Ú¯Ù‡ÛŒ Ø§Ø² ØµÙØ­Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª"""
    fields = {
        "Ø´Ù…Ø§Ø±Ù‡ Ù¾ÛŒÚ¯ÛŒØ±ÛŒ": driver.find_element(By.ID, "P28_REFERENCENUMBER").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_INDIKATORNUMBER").get_attribute("value"),
        "ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_SABTDATE").get_attribute("value"),
        "Ù†Ø§Ù… Ø´Ø±Ú©Øª": driver.find_element(By.ID, "P28_COMPANYNAME").get_attribute("value"),
        "Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ Ø´Ø±Ú©Øª": driver.find_element(By.ID, "P28_SABTNATIONALID").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ø«Ø¨Øª": driver.find_element(By.ID, "P28_SABTNUMBER").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_NEWSPAPERNO").get_attribute("value"),
        "ØªØ§Ø±ÛŒØ® Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_NEWSPAPERDATE").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_PAGENUMBER").get_attribute("value"),
        "ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¨Øª Ø§Ù†ØªØ´Ø§Ø±": driver.find_element(By.ID, "P28_HCNEWSSTAGE").get_attribute("value")
    }
    dynamic = soup.select_one("a-dynamic-content")
    fields["Ù…ØªÙ† Ø¢Ú¯Ù‡ÛŒ"] = dynamic.get_text(" ", strip=True) if dynamic else soup.get_text(" ", strip=True)
    return fields

def llm(data):
    import google.generativeai as genai
    from google.genai import types
    # 1ï¸âƒ£ --- Ø­Ø°Ù Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø± Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ ---
    os.environ["GRPC_VERBOSITY"] = "NONE"
    os.environ["GLOG_minloglevel"] = "2"
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

    # 2ï¸âƒ£ --- ØªÙ†Ø¸ÛŒÙ… API Key ---
    apikey = "AIzaSyAALSr7TI81SZ6e0X9tLk14GJJk37CkMgQ"
    genai.configure(api_key=apikey)

    # 3ï¸âƒ£ --- ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„ JSON Ø¨Ù‡ Ø±Ø´ØªÙ‡ (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ dict) ---
    prompt = json.dumps(data, ensure_ascii=False, indent=2)

    # 4ï¸âƒ£ --- ØªØ¹Ø±ÛŒÙ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø³ÛŒØ³ØªÙ… ---
    system_instruction = """Ù†Ù‚Ø´: Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù…ØªØ®ØµØµ Ø­Ù‚ÙˆÙ‚ÛŒ Ùˆ Ø´Ø±Ú©ØªÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø³Ù…ÛŒ Ùˆ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø«ÛŒØ±Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± ØªØ®ØµØµ Ø¯Ø§Ø±ÛŒØ¯.
    Ù…ÙˆØ¶ÙˆØ¹: ÙˆØ±ÙˆØ¯ÛŒ Ø­Ø§ÙˆÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ø«Ø¨Øªâ€ŒØ´Ø¯Ù‡ Ø¯Ø± Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ø±Ø³Ù…ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø´Ø±Ú©Øª Ø§Ø³Øª.
    ÙˆØ¸ÛŒÙÙ‡ Ø§ØµÙ„ÛŒ: Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø²Ù…Ø§Ù†ÛŒ Ù…ØªÙ† Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ØŒ Ù‡Ø± Ø¹Ø¶Ùˆ Ø§ÛŒÙ† Ø´Ø±Ú©Øª Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø¨Ø§ ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.

    Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø±Ø§:
    1. Ø§Ø¨ØªØ¯Ø§ ØªÙ…Ø§Ù… Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Â«ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡Â» ÛŒØ§ Â«ØªØ§Ø±ÛŒØ® Ø±ÙˆØ²Ù†Ø§Ù…Ù‡Â» Ø§Ø² Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø±ØªØ¨ Ú©Ù†ÛŒØ¯.
    2. Ù…ØªÙ† Ù‡Ø± Ø¢Ú¯Ù‡ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª (Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„ØŒ Ù‡ÛŒØ¦Øªâ€ŒÙ…Ø¯ÛŒØ±Ù‡ØŒ Ø¨Ø§Ø²Ø±Ø³ Ùˆ...) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆØ¯.
    3. Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ØŒ ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯.
    4. Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø²ÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯:
    {
    "Ù†Ø§Ù… Ø´Ø±Ú©Øª": "string or null",
    "Ø´Ù†Ø§Ø³Ù‡ Ø´Ø±Ú©Øª": "number or null",
    "Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª": [
        {"Ù†Ø§Ù…": "string or null", "Ú©Ø¯ Ù…Ù„ÛŒ": "string or null", "Ø³Ù…Øª": "string or null", "ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹": "string or null", "ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†": "string or null", "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": "string or null"}
    ],
    "Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª": [
        {"Ù†Ø§Ù…": "string or null", "Ú©Ø¯ Ù…Ù„ÛŒ": "string or null", "Ø³Ù…Øª": "string or null", "ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹": "string or null", "ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†": "string or null", "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": "string or null"}
    ]
    }
    """

    # 5ï¸âƒ£ --- Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Gemini ---
    model = genai.GenerativeModel(
        model_name="gemini-2.5-pro",
        system_instruction=system_instruction
    )

    # 6ï¸âƒ£ --- ØªÙˆÙ„ÛŒØ¯ Ø®Ø±ÙˆØ¬ÛŒ JSON ---
    response = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0.2
        }
    )

    # 7ï¸âƒ£ --- Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ ---
    output_path = "company_members.json"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(response.text)

    # 8ï¸âƒ£ --- Ú†Ø§Ù¾ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ ---
    print("âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
    print(f"ğŸ“ Ø®Ø±ÙˆØ¬ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {output_path}")

# ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
def shamsi_to_miladi(date_str):
    """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ"""
    if date_str is None or date_str == 'null':
        return datetime.now()

    try:
        parts = date_str.split('/')
        year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
        j_date = jdatetime.date(year, month, day)
        return j_date.togregorian()
    except Exception as e:
        return datetime.now()

def charts(data):
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    if not data or 'Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª' not in data:
        print("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³ØªÙ†Ø¯.")
        return
    
    members = data['Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª']
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ DataFrame
    df = pd.DataFrame(members)
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø±Ø³Øª ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§
    df['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'] = df['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹'].apply(shamsi_to_miladi)
    df['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'] = df['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'].apply(shamsi_to_miladi)

    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø¹Ø¶Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù…Øª
    def categorize_position(position):
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ù…Øªâ€ŒÙ‡Ø§"""
        if 'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„' in position:
            return 'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„'
        elif any(x in position for x in ['Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª', 'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª', 'Ù†Ø§ÛŒØ¨', 'Ù†Ø§Ø¦Ø¨', 'Ø¹Ø¶Ùˆ Ù‡ÛŒØ¦Øª', 'Ø¹Ø¶Ùˆ Ù‡ÛŒØ§Øª']):
            return 'Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡'
        elif 'Ø¨Ø§Ø²Ø±Ø³' in position:
            return 'Ø¨Ø§Ø²Ø±Ø³'
        else:
            return 'Ø³Ø§ÛŒØ±'

    df['Ø¯Ø³ØªÙ‡'] = df['Ø³Ù…Øª'].apply(categorize_position)
    df = df.sort_values('ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ')

    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø§ Plotly
    fig = make_subplots(
        rows=3, cols=1,
        row_heights=[0.5, 0.3, 0.2],
        subplot_titles=(
            'ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª',
            'ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡ Ùˆ Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„',
            'Ø¢Ù…Ø§Ø± Ø³Ù…Øªâ€ŒÙ‡Ø§'
        ),
        specs=[[{"type": "scatter"}],
            [{"type": "scatter"}],
            [{"type": "bar"}]],
        vertical_spacing=0.12
    )

    # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    color_map = {
        'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#1f77b4',
        'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#1f77b4',
        'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„': '#ff7f0e',
        'Ù†Ø§ÛŒØ¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ù†Ø§Ø¦Ø¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ù†Ø§Ø¦Ø¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ø¹Ø¶Ùˆ Ø§ØµÙ„ÛŒ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#d62728',
        'Ø¹Ø¶Ùˆ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#9467bd',
        'Ø¹Ø¶Ùˆ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#9467bd',
        'Ø¨Ø§Ø²Ø±Ø³ Ø§ØµÙ„ÛŒ': '#8c564b',
        'Ø¨Ø§Ø²Ø±Ø³ Ø¹Ù„ÛŒ Ø§Ù„Ø¨Ø¯Ù„': '#e377c2'
    }

    # Ù†Ù…ÙˆØ¯Ø§Ø± 1: ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„
    for idx, row in df.iterrows():
        color = color_map.get(row['Ø³Ù…Øª'], '#7f7f7f')

        fig.add_trace(
            go.Scatter(
                x=[row['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'], row['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ']],
                y=[row['Ù†Ø§Ù…'], row['Ù†Ø§Ù…']],
                mode='lines+markers',
                name=row['Ø³Ù…Øª'],
                line=dict(color=color, width=6),
                marker=dict(size=8, color=color),
                hovertemplate=(
                    f"<b>{row['Ù†Ø§Ù…']}</b><br>"
                    f"Ø³Ù…Øª: {row['Ø³Ù…Øª']}<br>"
                    f"Ø´Ø±ÙˆØ¹: {row['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹']}<br>"
                    f"Ù¾Ø§ÛŒØ§Ù†: {row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] if row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] else 'Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯'}<br>"
                    "<extra></extra>"
                ),
                showlegend=False
            ),
            row=1, col=1
        )

    # Ù†Ù…ÙˆØ¯Ø§Ø± 2: ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡ Ùˆ Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„
    for idx, row in df.iterrows():
        color = color_map.get(row['Ø³Ù…Øª'], '#7f7f7f')

        fig.add_trace(
            go.Scatter(
                x=[row['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'], row['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ']],
                y=[f"{row['Ù†Ø§Ù…']} - {row['Ø³Ù…Øª']}", f"{row['Ù†Ø§Ù…']} - {row['Ø³Ù…Øª']}"],
                mode='lines+markers',
                name=row['Ø³Ù…Øª'],
                line=dict(color=color, width=8),
                marker=dict(size=10, color=color),
                hovertemplate=(
                    f"<b>{row['Ù†Ø§Ù…']}</b><br>"
                    f"Ø³Ù…Øª: {row['Ø³Ù…Øª']}<br>"
                    f"Ø´Ø±ÙˆØ¹: {row['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹']}<br>"
                    f"Ù¾Ø§ÛŒØ§Ù†: {row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] if row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] else 'Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯'}<br>"
                    "<extra></extra>"
                ),
                showlegend=False
            ),
            row=2, col=1
        )

    # Ù†Ù…ÙˆØ¯Ø§Ø± 3: Ø¢Ù…Ø§Ø± Ø³Ù…Øªâ€ŒÙ‡Ø§
    position_counts = df['Ø³Ù…Øª'].value_counts()
    fig.add_trace(
        go.Bar(
            x=position_counts.index,
            y=position_counts.values,
            marker_color='#636EFA',
            text=position_counts.values,
            textposition='auto',
            hovertemplate="<b>%{x}</b><br>ØªØ¹Ø¯Ø§Ø¯: %{y}<extra></extra>",
            showlegend=False
        ),
        row=3, col=1
    )

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´
    fig.update_xaxes(title_text="Ø²Ù…Ø§Ù†", row=1, col=1)
    fig.update_xaxes(title_text="Ø²Ù…Ø§Ù†", row=2, col=1)
    fig.update_xaxes(title_text="Ø³Ù…Øª", tickangle=45, row=3, col=1)

    fig.update_yaxes(title_text="Ù†Ø§Ù… Ø¹Ø¶Ùˆ", row=1, col=1)
    fig.update_yaxes(title_text="Ù†Ø§Ù… Ùˆ Ø³Ù…Øª", row=2, col=1)
    fig.update_yaxes(title_text="ØªØ¹Ø¯Ø§Ø¯", row=3, col=1)

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ
    fig.update_layout(
        title_text="<b>Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª</b>",
        title_font_size=24,
        height=1400,
        showlegend=False,
        hovermode='closest',
        template='plotly_white',
        font=dict(family="Tahoma", size=11)
    )

    # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
    fig.show()


# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit
st.title("ğŸ¢ RRK.ir â€“ Company Ads Extractor & Analyzer")

tab1, tab2, tab3 = st.tabs(["ğŸ•µï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø±Ú©Øª", "ğŸ“‚ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª", "ØªØ§ÛŒÙ… Ù„Ø§ÛŒÙ† Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª"])

# ØªØ¨ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÛŒØ¯
with tab1:
    st.markdown("Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† **Ù†Ø§Ù… Ø´Ø±Ú©Øª** ÛŒØ§ **Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ**ØŒ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø§Ø² rrk.ir Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ú©Ù†ÛŒØ¯.")
    query = st.text_input("ğŸ” Ù†Ø§Ù… Ø´Ø±Ú©Øª ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ:")
    start_btn = st.button("Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬")

    if start_btn:
        if not query.strip():
            st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ø´Ø±Ú©Øª ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        else:
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ Ø§Ø² rrk.ir ..."):
                ads = scrape_company_ads(query)

            if len(ads) == 0:
                st.error("âŒ Ù‡ÛŒÚ† Ø¢Ú¯Ù‡ÛŒâ€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else:
                df = pd.DataFrame(ads)
                st.success(f"âœ… {len(df)} Ø¢Ú¯Ù‡ÛŒ ÛŒØ§ÙØª Ø´Ø¯.")
                st.dataframe(df)

                json_data = json.dumps(ads, ensure_ascii=False, indent=2)
                st.download_button(
                    "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ JSON",
                    data=json_data,
                    file_name=f"{query}_ads.json",
                    mime="application/json"
                )

                excel_bytes = df.to_excel(index=False, engine="openpyxl")
                st.download_button(
                    "ğŸ“Š Ø¯Ø§Ù†Ù„ÙˆØ¯ Excel",
                    data=excel_bytes,
                    file_name=f"{query}_ads.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

# ØªØ¨ 2: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ JSON
with tab2:
    st.markdown("ÙØ§ÛŒÙ„ JSON Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ø±Ø³Ù…ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    uploaded = st.file_uploader("ğŸ“‚ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["json"], key="file_uploader_1")

    if uploaded is not None:
        try:
            ads = json.load(uploaded)
            st.success(f"âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ {len(ads)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            st.dataframe(pd.DataFrame(ads))

            # Ù†Ù…Ø§ÛŒØ´ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡
            st.markdown("### ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡")
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§:**", len(set([ad["Ù†Ø§Ù… Ø´Ø±Ú©Øª"] for ad in ads])))
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§:**", len(ads))

            llm(ads)
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø±Ú©Øª: {e}")

# ØªØ¨ 3: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª
with tab3:
    st.markdown("ÙØ§ÛŒÙ„ JSON Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯")
    uploaded2 = st.file_uploader("ğŸ“‚ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["json"], key="file_uploader_2")

    if uploaded2 is not None:
        try:
            dataframe = json.load(uploaded2)
            charts(dataframe)
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ú†Ø§Ø±Øª : {e}")



