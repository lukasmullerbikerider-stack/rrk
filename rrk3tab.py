import os
import time
import json
import logging
import streamlit as st
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import undetected_chromedriver as uc


# -----------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Chrome
# -----------------------------
def setup_driver(headless=True):
    chrome_options = Options()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--lang=fa-IR")
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                                "AppleWebKit/537.36 (KHTML, like Gecko) "
                                "Chrome/118.0.5993.70 Safari/537.36")
    if headless:
        chrome_options.add_argument("--headless=new")

    driver = webdriver.Chrome(options=chrome_options)
    driver.set_window_size(1920, 1080)
    driver.implicitly_wait(10)
    wait = WebDriverWait(driver, 60)
    return driver, wait

# -----------------------------
# Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
# -----------------------------
def save_debug(driver, name):
    """Ø°Ø®ÛŒØ±Ù‡ Ø§Ø³Ú©Ø±ÛŒÙ†â€ŒØ´Ø§Øª Ùˆ HTML Ø¯Ø± Ù¾ÙˆØ´Ù‡ debug"""
    os.makedirs("debug", exist_ok=True)
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    base = f"debug/{timestamp}_{name}"
    try:
        driver.save_screenshot(f"{base}.png")
        with open(f"{base}.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        logging.info(f"ğŸ“¸ Debug saved: {base}")
    except Exception as e:
        logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ debug: {e}")

# -----------------------------
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# -----------------------------
def get_links(driver):
    soup = BeautifulSoup(driver.page_source, "html.parser")
    return soup.select("a[href*='/ords/r/rrs/rrs-front/f-detail-ad']")

def extract_fields(driver, soup):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¢Ú¯Ù‡ÛŒ Ø§Ø² ØµÙØ­Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª"""
    fields = {
        "Ø´Ù…Ø§Ø±Ù‡ Ù¾ÛŒÚ¯ÛŒØ±ÛŒ": driver.find_element(By.ID, "P28_REFERENCENUMBER").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_INDIKATORNUMBER").get_attribute("value"),
        "ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_SABTDATE").get_attribute("value"),
        "Ù†Ø§Ù… Ø´Ø±Ú©Øª": driver.find_element(By.ID, "P28_COMPANYNAME").get_attribute("value"),
        "Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ Ø´Ø±Ú©Øª": driver.find_element(By.ID, "P28_SABTNATIONALID").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ø«Ø¨Øª": driver.find_element(By.ID, "P28_SABTNUMBER").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_NEWSPAPERNO").get_attribute("value"),
        "ØªØ§Ø±ÛŒØ® Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_NEWSPAPERDATE").get_attribute("value"),
        "Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": driver.find_element(By.ID, "P28_PAGENUMBER").get_attribute("value"),
        "ØªØ¹Ø¯Ø§Ø¯ Ù†ÙˆØ¨Øª Ø§Ù†ØªØ´Ø§Ø±": driver.find_element(By.ID, "P28_HCNEWSSTAGE").get_attribute("value")
    }
    dynamic = soup.select_one("a-dynamic-content")
    fields["Ù…ØªÙ† Ø¢Ú¯Ù‡ÛŒ"] = dynamic.get_text(" ", strip=True) if dynamic else soup.get_text(" ", strip=True)
    return fields

# -----------------------------
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
# -----------------------------
def scrape_company_ads(query, headless=True):
    driver, wait = setup_driver(headless=headless)
    ad_data = []

    try:
        logging.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± rrk.ir ...")
        driver.get("https://www.rrk.ir/")
        time.sleep(2)
        save_debug(driver, "home")

        search_box = wait.until(EC.presence_of_element_located((By.ID, "P0_SEARCH_ITEM")))
        search_box.clear()
        search_box.send_keys(query)
        driver.find_element(By.ID, "BTN_ADVANCEDSEARCH").click()

        time.sleep(3)
        wait.until(EC.element_to_be_clickable((By.CLASS_NAME, "t-LinksList-link"))).click()
        time.sleep(3)
        save_debug(driver, "results_page")

        current_page = 1
        while True:
            ad_links = get_links(driver)
            if not ad_links:
                logging.info("ğŸš« Ø¢Ú¯Ù‡ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                save_debug(driver, f"no_ads_page_{current_page}")
                break

            for tag in ad_links:
                href = tag.get("href")
                if not href.startswith("/ords/r/rrs/rrs-front/f-detail-ad"):
                    continue
                url = "https://rrk.ir" + href

                driver.execute_script("window.open('');")
                driver.switch_to.window(driver.window_handles[1])
                driver.get(url)

                try:
                    soup = BeautifulSoup(driver.page_source, "html.parser")
                    data = extract_fields(driver, soup)
                    data["url"] = url
                    ad_data.append(data)
                    logging.info(f"âœ… Ø¢Ú¯Ù‡ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {url}")
                except Exception as e:
                    logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ú¯Ù‡ÛŒ: {e}")
                    save_debug(driver, "ad_error")
                finally:
                    driver.close()
                    driver.switch_to.window(driver.window_handles[0])
                    time.sleep(1.5)

            next_buttons = driver.find_elements(By.CSS_SELECTOR, "ul.a-GV-pageSelector-list li button.a-GV-pageButton")
            next_btn = next((b for b in next_buttons if b.text.isdigit() and int(b.text) == current_page + 1), None)
            if not next_btn:
                logging.info("ğŸ“„ ØµÙØ­Ù‡ Ø¨Ø¹Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                break
            driver.execute_script("arguments[0].click();", next_btn)
            current_page += 1
            time.sleep(5)

    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ú©Ù„ÛŒ: {e}")
        save_debug(driver, "fatal_error")
    finally:
        driver.quit()

    return ad_data

def llm(data):
    import google.generativeai as genai
    from google.genai import types
    # 1ï¸âƒ£ --- Ø­Ø°Ù Ú©Ø§Ù…Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù‡Ø´Ø¯Ø§Ø± Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ ---
    os.environ["GRPC_VERBOSITY"] = "NONE"
    os.environ["GLOG_minloglevel"] = "2"
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

    # 2ï¸âƒ£ --- ØªÙ†Ø¸ÛŒÙ… API Key ---
    apikey = "AIzaSyAALSr7TI81SZ6e0X9tLk14GJJk37CkMgQ"
    genai.configure(api_key=apikey)

    # 3ï¸âƒ£ --- ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„ JSON Ø¨Ù‡ Ø±Ø´ØªÙ‡ (Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ dict) ---
    prompt = json.dumps(data, ensure_ascii=False, indent=2)

    # 4ï¸âƒ£ --- ØªØ¹Ø±ÛŒÙ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø³ÛŒØ³ØªÙ… ---
    system_instruction = """Ù†Ù‚Ø´: Ø´Ù…Ø§ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù…ØªØ®ØµØµ Ø­Ù‚ÙˆÙ‚ÛŒ Ùˆ Ø´Ø±Ú©ØªÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø³Ù…ÛŒ Ùˆ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø«ÛŒØ±Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± ØªØ®ØµØµ Ø¯Ø§Ø±ÛŒØ¯.
    Ù…ÙˆØ¶ÙˆØ¹: ÙˆØ±ÙˆØ¯ÛŒ Ø­Ø§ÙˆÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ø«Ø¨Øªâ€ŒØ´Ø¯Ù‡ Ø¯Ø± Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ø±Ø³Ù…ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø´Ø±Ú©Øª Ø§Ø³Øª.
    ÙˆØ¸ÛŒÙÙ‡ Ø§ØµÙ„ÛŒ: Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø²Ù…Ø§Ù†ÛŒ Ù…ØªÙ† Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ØŒ Ù‡Ø± Ø¹Ø¶Ùˆ Ø§ÛŒÙ† Ø´Ø±Ú©Øª Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø¨Ø§ ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ù…Ø¹Ø±ÙÛŒ Ú©Ù†ÛŒØ¯.

    Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø±Ø§:
    1. Ø§Ø¨ØªØ¯Ø§ ØªÙ…Ø§Ù… Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Â«ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡Â» ÛŒØ§ Â«ØªØ§Ø±ÛŒØ® Ø±ÙˆØ²Ù†Ø§Ù…Ù‡Â» Ø§Ø² Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¨Ù‡ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ø±ØªØ¨ Ú©Ù†ÛŒØ¯.
    2. Ù…ØªÙ† Ù‡Ø± Ø¢Ú¯Ù‡ÛŒ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª (Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„ØŒ Ù‡ÛŒØ¦Øªâ€ŒÙ…Ø¯ÛŒØ±Ù‡ØŒ Ø¨Ø§Ø²Ø±Ø³ Ùˆ...) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆØ¯.
    3. Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ØŒ ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯.
    4. Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON Ø²ÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ú©Ù†ÛŒØ¯:
    {
    "Ù†Ø§Ù… Ø´Ø±Ú©Øª": "string or null",
    "Ø´Ù†Ø§Ø³Ù‡ Ø´Ø±Ú©Øª": "number or null",
    "Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª": [
        {"Ù†Ø§Ù…": "string or null", "Ú©Ø¯ Ù…Ù„ÛŒ": "string or null", "Ø³Ù…Øª": "string or null", "ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹": "string or null", "ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†": "string or null", "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": "string or null"}
    ],
    "Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª": [
        {"Ù†Ø§Ù…": "string or null", "Ú©Ø¯ Ù…Ù„ÛŒ": "string or null", "Ø³Ù…Øª": "string or null", "ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹": "string or null", "ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†": "string or null", "Ø´Ù…Ø§Ø±Ù‡ Ø±ÙˆØ²Ù†Ø§Ù…Ù‡": "string or null"}
    ]
    }
    """

    # 5ï¸âƒ£ --- Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Gemini ---
    model = genai.GenerativeModel(
        model_name="gemini-1.5-pro",  # ØªØµØ­ÛŒØ­ Ù…Ø¯Ù„ Ø¨Ù‡ Ù†Ø³Ø®Ù‡ Ù…Ø¹ØªØ¨Ø±
        system_instruction=system_instruction
    )

    # 6ï¸âƒ£ --- ØªÙˆÙ„ÛŒØ¯ Ø®Ø±ÙˆØ¬ÛŒ JSON ---
    response = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0.2
        }
    )

    # 7ï¸âƒ£ --- Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ ---
    output_path = "company_members.json"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(response.text)

    # 8ï¸âƒ£ --- Ø¨Ø§Ø²Ú¯Ø´Øª Ù…Ø­ØªÙˆØ§ÛŒ JSON Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Streamlit ---
    with open(output_path, "r", encoding="utf-8") as f:
        return json.load(f)

# ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
def shamsi_to_miladi(date_str):
    """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ"""
    if date_str is None or date_str == 'null':
        return datetime.now()

    try:
        parts = date_str.split('/')
        year, month, day = int(parts[0]), int(parts[1]), int(parts[2])
        j_date = jdatetime.date(year, month, day)
        return j_date.togregorian()
    except Exception as e:
        return datetime.now()

def charts(data):
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    if not data or ('Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª' not in data and 'Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª' not in data):
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³ØªÙ†Ø¯. Ù„Ø·ÙØ§Ù‹ JSON Ù…Ø¹ØªØ¨Ø± Ø­Ø§ÙˆÛŒ 'Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª' ÛŒØ§ 'Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª' Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
        return
    
    # ØªØ±Ú©ÛŒØ¨ Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ùˆ Ø³Ø§Ø¨Ù‚
    all_members = []
    if 'Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª' in data:
        all_members.extend(data['Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø´Ø±Ú©Øª'])
    if 'Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª' in data:
        all_members.extend(data['Ø§Ø¹Ø¶Ø§ÛŒ Ø³Ø§Ø¨Ù‚ Ø´Ø±Ú©Øª'])
    
    if not all_members:
        st.warning("âš ï¸ Ù‡ÛŒÚ† Ø¹Ø¶ÙˆÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return
    
    # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ DataFrame
    df = pd.DataFrame(all_members)
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø±Ø³Øª ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§
    df['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'] = df['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹'].apply(shamsi_to_miladi)
    df['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'] = df['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'].apply(shamsi_to_miladi)

    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø¹Ø¶Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù…Øª
    def categorize_position(position):
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ù…Øªâ€ŒÙ‡Ø§"""
        if 'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„' in position:
            return 'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„'
        elif any(x in position for x in ['Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª', 'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª', 'Ù†Ø§ÛŒØ¨', 'Ù†Ø§Ø¦Ø¨', 'Ø¹Ø¶Ùˆ Ù‡ÛŒØ¦Øª', 'Ø¹Ø¶Ùˆ Ù‡ÛŒØ§Øª']):
            return 'Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡'
        elif 'Ø¨Ø§Ø²Ø±Ø³' in position:
            return 'Ø¨Ø§Ø²Ø±Ø³'
        else:
            return 'Ø³Ø§ÛŒØ±'

    df['Ø¯Ø³ØªÙ‡'] = df['Ø³Ù…Øª'].apply(categorize_position)
    df = df.sort_values('ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ')

    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø§ Plotly
    fig = make_subplots(
        rows=3, cols=1,
        row_heights=[0.5, 0.3, 0.2],
        subplot_titles=(
            'ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª',
            'ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡ Ùˆ Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„',
            'Ø¢Ù…Ø§Ø± Ø³Ù…Øªâ€ŒÙ‡Ø§'
        ),
        specs=[[{"type": "scatter"}],
            [{"type": "scatter"}],
            [{"type": "bar"}]],
        vertical_spacing=0.12
    )

    # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    color_map = {
        'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#1f77b4',
        'Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#1f77b4',
        'Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„': '#ff7f0e',
        'Ù†Ø§ÛŒØ¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ù†Ø§Ø¦Ø¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ù†Ø§Ø¦Ø¨ Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#2ca02c',
        'Ø¹Ø¶Ùˆ Ø§ØµÙ„ÛŒ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#d62728',
        'Ø¹Ø¶Ùˆ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡': '#9467bd',
        'Ø¹Ø¶Ùˆ Ù‡ÛŒØ§Øª Ù…Ø¯ÛŒØ±Ù‡': '#9467bd',
        'Ø¨Ø§Ø²Ø±Ø³ Ø§ØµÙ„ÛŒ': '#8c564b',
        'Ø¨Ø§Ø²Ø±Ø³ Ø¹Ù„ÛŒ Ø§Ù„Ø¨Ø¯Ù„': '#e377c2'
    }

    # Ù†Ù…ÙˆØ¯Ø§Ø± 1: ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ú©Ø§Ù…Ù„
    for idx, row in df.iterrows():
        color = color_map.get(row['Ø³Ù…Øª'], '#7f7f7f')

        fig.add_trace(
            go.Scatter(
                x=[row['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'], row['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ']],
                y=[row['Ù†Ø§Ù…'], row['Ù†Ø§Ù…']],
                mode='lines+markers',
                name=row['Ø³Ù…Øª'],
                line=dict(color=color, width=6),
                marker=dict(size=8, color=color),
                hovertemplate=(
                    f"<b>{row['Ù†Ø§Ù…']}</b><br>"
                    f"Ø³Ù…Øª: {row['Ø³Ù…Øª']}<br>"
                    f"Ø´Ø±ÙˆØ¹: {row['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹']}<br>"
                    f"Ù¾Ø§ÛŒØ§Ù†: {row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] if row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] else 'Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯'}<br>"
                    "<extra></extra>"
                ),
                showlegend=False
            ),
            row=1, col=1
        )

    # Ù†Ù…ÙˆØ¯Ø§Ø± 2: ØªØ§ÛŒÙ…â€ŒÙ„Ø§ÛŒÙ† Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª Ù…Ø¯ÛŒØ±Ù‡ Ùˆ Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„
    key_positions = df[df['Ø³Ù…Øª'].str.contains('Ù…Ø¯ÛŒØ±Ø¹Ø§Ù…Ù„|Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ¦Øª|Ø±Ø¦ÛŒØ³ Ù‡ÛŒØ§Øª', na=False)]
    for idx, row in key_positions.iterrows():
        color = color_map.get(row['Ø³Ù…Øª'], '#7f7f7f')

        fig.add_trace(
            go.Scatter(
                x=[row['ØªØ§Ø±ÛŒØ®_Ø´Ø±ÙˆØ¹_Ù…ÛŒÙ„Ø§Ø¯ÛŒ'], row['ØªØ§Ø±ÛŒØ®_Ù¾Ø§ÛŒØ§Ù†_Ù…ÛŒÙ„Ø§Ø¯ÛŒ']],
                y=[f"{row['Ù†Ø§Ù…']} - {row['Ø³Ù…Øª']}", f"{row['Ù†Ø§Ù…']} - {row['Ø³Ù…Øª']}"],
                mode='lines+markers',
                name=row['Ø³Ù…Øª'],
                line=dict(color=color, width=8),
                marker=dict(size=10, color=color),
                hovertemplate=(
                    f"<b>{row['Ù†Ø§Ù…']}</b><br>"
                    f"Ø³Ù…Øª: {row['Ø³Ù…Øª']}<br>"
                    f"Ø´Ø±ÙˆØ¹: {row['ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹']}<br>"
                    f"Ù¾Ø§ÛŒØ§Ù†: {row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] if row['ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†'] else 'Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯'}<br>"
                    "<extra></extra>"
                ),
                showlegend=False
            ),
            row=2, col=1
        )

    # Ù†Ù…ÙˆØ¯Ø§Ø± 3: Ø¢Ù…Ø§Ø± Ø³Ù…Øªâ€ŒÙ‡Ø§
    position_counts = df['Ø³Ù…Øª'].value_counts()
    fig.add_trace(
        go.Bar(
            x=position_counts.index,
            y=position_counts.values,
            marker_color='#636EFA',
            text=position_counts.values,
            textposition='auto',
            hovertemplate="<b>%{x}</b><br>ØªØ¹Ø¯Ø§Ø¯: %{y}<extra></extra>",
            showlegend=False
        ),
        row=3, col=1
    )

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´
    fig.update_xaxes(title_text="Ø²Ù…Ø§Ù†", row=1, col=1)
    fig.update_xaxes(title_text="Ø²Ù…Ø§Ù†", row=2, col=1)
    fig.update_xaxes(title_text="Ø³Ù…Øª", tickangle=45, row=3, col=1)

    fig.update_yaxes(title_text="Ù†Ø§Ù… Ø¹Ø¶Ùˆ", row=1, col=1)
    fig.update_yaxes(title_text="Ù†Ø§Ù… Ùˆ Ø³Ù…Øª", row=2, col=1)
    fig.update_yaxes(title_text="ØªØ¹Ø¯Ø§Ø¯", row=3, col=1)

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ
    fig.update_layout(
        title_text="<b>Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª</b>",
        title_font_size=24,
        height=1400,
        showlegend=False,
        hovermode='closest',
        template='plotly_white',
        font=dict(family="Tahoma", size=11)
    )

    # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¯Ø± Streamlit
    st.plotly_chart(fig, use_container_width=True)

# ----------------------------------
# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit
# ----------------------------------
st.title("ğŸ¢ RRK.ir â€“ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ø±Ø³Ù…ÛŒ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø§Ø·Ù„Ø§Ø¹ Ø±Ø³Ø§Ù†ÛŒ Ø§Ø¹Ø¶Ø§ Ùˆ ØªØ§ÛŒÙ… Ù„Ø§ÛŒÙ†")

tab1, tab2, tab3 = st.tabs(["ğŸ•µï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø±Ú©Øª", "ğŸ“‚ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª", "ØªØ§ÛŒÙ… Ù„Ø§ÛŒÙ† Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª"])

# --------------------------
# ØªØ¨ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÛŒØ¯
# --------------------------
with tab1:
    st.markdown("Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† **Ù†Ø§Ù… Ø´Ø±Ú©Øª** ÛŒØ§ **Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ**ØŒ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ø§Ø² rrk.ir Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ú©Ù†ÛŒØ¯.")
    query = st.text_input("ğŸ” Ù†Ø§Ù… Ø´Ø±Ú©Øª ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ:")
    start_btn = st.button("Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬")

    if start_btn:
        if not query.strip():
            st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ø´Ø±Ú©Øª ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ù…Ù„ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        else:
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ Ø§Ø² rrk.ir ..."):
                ads = scrape_company_ads(query)

            if len(ads) == 0:
                st.error("âŒ Ù‡ÛŒÚ† Ø¢Ú¯Ù‡ÛŒâ€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            else:
                df = pd.DataFrame(ads)
                st.success(f"âœ… {len(df)} Ø¢Ú¯Ù‡ÛŒ ÛŒØ§ÙØª Ø´Ø¯.")
                st.dataframe(df)

                json_data = json.dumps(ads, ensure_ascii=False, indent=2)
                st.download_button(
                    "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ JSON",
                    data=json_data,
                    file_name=f"{query}_ads.json",
                    mime="application/json"
                )

                excel_bytes = df.to_excel(index=False, engine="openpyxl")
                st.download_button(
                    "ğŸ“Š Ø¯Ø§Ù†Ù„ÙˆØ¯ Excel",
                    data=excel_bytes,
                    file_name=f"{query}_ads.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

# --------------------------
# ØªØ¨ 2: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ JSON
# --------------------------
with tab2:
    st.markdown("Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.")
    uploaded = st.file_uploader("ğŸ“‚ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["json"])

    if uploaded is not None:
        try:
            ads = json.load(uploaded)
            df = pd.DataFrame(ads)
            st.success(f"âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ {len(df)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            st.dataframe(df)

            # Ù†Ù…Ø§ÛŒØ´ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡
            st.markdown("### ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡")
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§:**", df["Ù†Ø§Ù… Ø´Ø±Ú©Øª"].nunique())
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§:**", len(df))
            st.write("**Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ:**", f"{df['ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡'].min()} ØªØ§ {df['ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ù‡'].max()}")

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ LLM Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø®Ø±ÙˆØ¬ÛŒ
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ..."):
                analyzed_data = llm(ads)
            
            st.markdown("### ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª")
            st.json(analyzed_data)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ
            with open("company_members.json", "r", encoding="utf-8") as f:
                json_content = f.read()
            st.download_button(
                "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ JSON ØªØ­Ù„ÛŒÙ„â€ŒØ´Ø¯Ù‡",
                data=json_content,
                file_name="company_members.json",
                mime="application/json"
            )
            
            # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø±Ú©Øª ÛŒØ§ ØªØ§Ø±ÛŒØ®
            company_filter = st.selectbox("ğŸ¢ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø±Ú©Øª", df["Ù†Ø§Ù… Ø´Ø±Ú©Øª"].unique())
            df_filtered = df[df["Ù†Ø§Ù… Ø´Ø±Ú©Øª"] == company_filter]
            st.dataframe(df_filtered)


            # Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¬Ø¯Ø¯
            st.download_button(
                "ğŸ“¤ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÛŒÙ„ØªØ±Ø´Ø¯Ù‡ (Excel)",
                data=df_filtered.to_csv(index=False).encode("utf-8"),
                file_name=f"{company_filter}_filtered.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")

# ØªØ¨ 2: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ JSON
with tab2:
    st.markdown("ÙØ§ÛŒÙ„ JSON Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±ÙˆØ²Ù†Ø§Ù…Ù‡ Ø±Ø³Ù…ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
    uploaded = st.file_uploader("ğŸ“‚ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["json"], key="file_uploader_1")

    if uploaded is not None:
        try:
            ads = json.load(uploaded)
            st.success(f"âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ {len(ads)} Ø±Ú©ÙˆØ±Ø¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            st.dataframe(pd.DataFrame(ads))

            # Ù†Ù…Ø§ÛŒØ´ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡
            st.markdown("### ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡")
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§:**", len(set([ad["Ù†Ø§Ù… Ø´Ø±Ú©Øª"] for ad in ads])))
            st.write("**ØªØ¹Ø¯Ø§Ø¯ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§:**", len(ads))

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ LLM Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø®Ø±ÙˆØ¬ÛŒ
            with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ..."):
                analyzed_data = llm(ads)
            
            st.markdown("### ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª")
            st.json(analyzed_data)
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ
            with open("company_members.json", "r", encoding="utf-8") as f:
                json_content = f.read()
            st.download_button(
                "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ JSON ØªØ­Ù„ÛŒÙ„â€ŒØ´Ø¯Ù‡",
                data=json_content,
                file_name="company_members.json",
                mime="application/json"
            )
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø±Ú©Øª: {e}")

# ØªØ¨ 3: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª
with tab3:
    st.markdown("ÙØ§ÛŒÙ„ JSON Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯")
    uploaded2 = st.file_uploader("ğŸ“‚ ÙØ§ÛŒÙ„ JSON Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=["json"], key="file_uploader_2")

    if uploaded2 is not None:
        try:
            dataframe = json.load(uploaded2)
            st.success("âœ… ÙØ§ÛŒÙ„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯...")
            charts(dataframe)
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ú†Ø§Ø±Øª: {e}")

tab1, tab2, tab3 = st.tabs(["ğŸ•µï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø±Ú©Øª", "ğŸ“‚ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª", "ØªØ§ÛŒÙ… Ù„Ø§ÛŒÙ† Ø§Ø¹Ø¶Ø§ÛŒ Ø´Ø±Ú©Øª"])
